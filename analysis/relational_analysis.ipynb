{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bc86ba",
   "metadata": {},
   "source": [
    "# Relational Analysis\n",
    "\n",
    "Using encodings generated by USE ML v3 encoder for:\n",
    "\n",
    "- Constitution segments\n",
    "- CCP reference topics (concatenated label and descriptions)\n",
    "- Comparison topic sets (concatenated label and descriptions)\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Discover semantic coverage gaps in a reference ontology by using a comparison ontology to audit the reference ontology.\n",
    "\n",
    "### Process Outline\n",
    "1. **Reference ontology**: Designed to code corpus segments.\n",
    "2. **Comparison ontology**: Alternative topic framework.\n",
    "3. **Find non-overlapping topics**: Comparison topics with zero co-occurrences with reference topics.\n",
    "4. **Gap identification**: These comparison topics capture segments that your reference ontology misses.\n",
    "5. **Validation**: Confirm reference ontology truly has no coverage of these segments.\n",
    "\n",
    "### What This Discovers\n",
    "- **Blind spots** in the reference ontology.\n",
    "- **Missing semantic categories** that comparison topics capture.\n",
    "- **Segments that fall through the cracks** of the reference system.\n",
    "\n",
    "### Chi-square Analysis\n",
    "\n",
    "In the co-occurrence matrix:\n",
    "- **High values**: Indicate overlap/redundancy between ontologies.\n",
    "- **Low values**: Indicate the ontologies are capturing different semantic spaces. Strong evidence that comparison topics are finding genuinely different content.\n",
    "\n",
    "The statistical significance of low chi-square values confirms that the comparison ontology is successfully identifying semantic content that the reference ontology systematically misses.\n",
    "\n",
    "\n",
    "Analysis is based on topic-segment matrices generated during ontology processing.\n",
    "\n",
    "Results can:\n",
    "\n",
    "1. Indicate the need for a new topic.\n",
    "2. If the comparison topic is a close match to a CCP reference topic then indicates segments that need to be tagged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715638f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Roy Gardner'\n",
    "__copyright__   = 'Copyright 2025, Roy and Sally Gardner'\n",
    "\n",
    "%run ./_library/packages.py\n",
    "%run ./_library/utilities.py\n",
    "\n",
    "exclusion_list = ['segment_encodings.json','IDEA-GLO_topic_encodings.json','CCP-FACET_topic_encodings.json',\\\n",
    "                     'NC-DCC_topic_encodings.json']\n",
    "_,model_dict = initialise(exclusion_list=exclusion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8dbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b6eff3",
   "metadata": {},
   "source": [
    "## Map segments onto tagged topics\n",
    "\n",
    "This gives us a human-coded segment-topic map from which we can check for human coding of segments that have no semantic relationship to a CCP topics but are semantically similar to a comparison topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042db02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the sat_segments_dict\n",
    "\n",
    "segments_lookup = {}\n",
    "for k,v in model_dict['sat_segments_dict'].items():\n",
    "    for segment_id in v:\n",
    "        if segment_id in segments_lookup:\n",
    "            segments_lookup[segment_id].append(k)\n",
    "        else:\n",
    "            segments_lookup[segment_id] = [k]\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7370f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2bfedd9",
   "metadata": {},
   "source": [
    "## Run the comparisons\n",
    "\n",
    "1. The reference ontology matrix is the topic-segment matrix for CCP topics. This matrix contains semantic similarity scores for all topic-segment pairs.\n",
    "2. For each comparison ontology we have a topic-segment matrix which is processed as follows:\n",
    "    - Threshold and binarise\n",
    "    - Generate the topic-topic co-occurrence matrix with comparison topics in rows and reference topics in columns.\n",
    " \n",
    "Outputs results to CSV.\n",
    "\n",
    "### Validation\n",
    "\n",
    "All CCP segments assigned to a comparison topic must be an empty column in matrix $\\mathbf{B}^{r,s}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7f4f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.70\n",
    "\n",
    "# Get the reference topic labels\n",
    "ref_labels = [v['encoded_text'] for k,v in model_dict['CCP-FACET_topics_dict'].items()]\n",
    "\n",
    "# Threshold and binarise the topic-segment matrix of the reference ontology\n",
    "A = np.array(model_dict['CCP-FACET_topic_segment_matrix'])\n",
    "B = np.where(A>=threshold,1,0).astype(int)\n",
    "\n",
    "\n",
    "# Now process the comparison matrices\n",
    "# Define the data structures for the comparison ontologies\n",
    "comparison_matrices = ['IDEA-GLO_topic_segment_matrix','NC-DCC_topic_segment_matrix']\n",
    "comparison_dicts = ['IDEA-GLO_topics_dict','NC-DCC_topics_dict']\n",
    "\n",
    "# Iterate the comparison ontologies\n",
    "for i,matrix_label in enumerate(comparison_matrices):\n",
    "    \n",
    "    # Get the topic labels for the comparison ontology\n",
    "    comp_labels = [v['encoded_text'] for k,v in model_dict[comparison_dicts[i]].items()]\n",
    "    # For results file and validation confirmation\n",
    "    ontology_label = matrix_label.split('_')[0]\n",
    "    \n",
    "    # Get the topic-segment matrix for our comparison ontology\n",
    "    C = np.array(model_dict[matrix_label])\n",
    "    # Threshold and binarise\n",
    "    D = np.where(C>=threshold,1,0).astype(int)\n",
    "    \n",
    "    # Co-occurrence matrix with comparison topics in rows and reference topics in columns\n",
    "    E = np.matmul(D,B.T)\n",
    "    \n",
    "    # Use to collect segments that are semantically similar to a comparison topic\n",
    "    segments_set = []\n",
    "\n",
    "    csv_row_list = []\n",
    "    header = []\n",
    "    header.append('comparison_topic')\n",
    "    header.append('segment_id')\n",
    "    header.append('segment_text')\n",
    "    header.append('tagged_ccp_topics')\n",
    "    csv_row_list.append(header)\n",
    "    \n",
    "    # Iterate comparison topics searching for empty rows in the co-occurrence matrix E.\n",
    "    # An empty row means that the comparison topic shares no segments with any CCP topic\n",
    "    for i,row in enumerate(E):\n",
    "        if row.nonzero()[0].size == 0:\n",
    "            # Get at- or above-threshold segments from the topic's row in topic-segment matrix D\n",
    "            segment_indices = [j for j,v in enumerate(D[i]) if v==1]\n",
    "            if len(segment_indices) == 0:\n",
    "                # Comparison topic is not semantically similar to any segment\n",
    "                continue\n",
    "            for j in segment_indices:\n",
    "                # Iterating the comparison topic's semantically similar segments\n",
    "                csv_row = []\n",
    "                csv_row.append(comp_labels[i])\n",
    "                segment_id = model_dict['encoded_segments'][j]\n",
    "                segments_set.append(segment_id)\n",
    "                segment_text = model_dict['segments_dict'][segment_id]['text']\n",
    "                csv_row.append(segment_id)\n",
    "                csv_row.append(segment_text)\n",
    "                # Check whether the segment has been manually tagged\n",
    "                if segment_id in segments_lookup:\n",
    "                    csv_row.append(str(segments_lookup[segment_id]))\n",
    "                else:\n",
    "                    csv_row.append('')\n",
    "                csv_row_list.append(csv_row)\n",
    "\n",
    "    # Validate the segment set by ensuring that each segment's column in the CCP topic-segment\n",
    "    # matrix comprises zeros only. This test ensures that a segment is not semantically similar to \n",
    "    # a CCP topic at or above threshold.\n",
    "    segments_set = list(set(segments_set))\n",
    "    n = 0\n",
    "    for segment_id in segments_set:\n",
    "        segment_index = model_dict['encoded_segments'].index(segment_id)\n",
    "        if B[:,segment_index].nonzero()[0].size == 0:\n",
    "            n += 1\n",
    "    assert(len(segments_set)==n)       \n",
    "    print('Validated',len(segments_set),'segments for',ontology_label)\n",
    "    \n",
    "    # Got through validation so write results to CSV file\n",
    "    with open('./outputs/' + ontology_label + '_candidates.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(csv_row_list)\n",
    "    f.close() \n",
    "    print('Data exported to CSV file:','./outputs/' + ontology_label + '_candidates.csv')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f11958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c60004e1",
   "metadata": {},
   "source": [
    "## Chi-square analysis\n",
    "\n",
    "We want low chi-square values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dc5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_matrix(matrix):\n",
    "    # Expected matrix assuming independence of topic sets\n",
    "    rows_marginal = matrix.sum(axis=1)\n",
    "    cols_marginal = matrix.sum(axis=0)\n",
    "    matrix_total = matrix.sum()\n",
    "    \n",
    "    # Calculate matrix of expected values under independence\n",
    "    expected = np.outer(rows_marginal,cols_marginal)/matrix_total\n",
    "    return expected\n",
    "\n",
    "# Threshold and binarise the topic-segment matrix of the reference ontology\n",
    "A = np.array(model_dict['CCP-FACET_topic_segment_matrix'])\n",
    "B = np.where(A>=threshold,1,0).astype(int)\n",
    "\n",
    "comparison_matrices = ['IDEA-GLO_topic_segment_matrix','NC-DCC_topic_segment_matrix']\n",
    "comparison_dicts = ['IDEA-GLO_topics_dict','NC-DCC_topics_dict']\n",
    "\n",
    "for i,matrix_label in enumerate(comparison_matrices):\n",
    "    ontology_label = matrix_label.split('_')[0]\n",
    "    print(ontology_label)\n",
    "    \n",
    "    C = np.array(model_dict[matrix_label])\n",
    "    # Threshold and binarise\n",
    "    D = np.where(C>=threshold,1,0).astype(int)\n",
    "    \n",
    "    E = np.matmul(D,B.T)\n",
    "    \n",
    "    # Now test independence on the shuffled matrix\n",
    "    expected = get_expected_matrix(E)\n",
    "    \n",
    "    # Add epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    expected_adjusted = expected + epsilon\n",
    "    chi2_stat = np.sum((E - expected_adjusted)**2 / expected_adjusted)\n",
    "    print('Observed chi-square',chi2_stat)\n",
    "    df = (E.shape[0] - 1) * (E.shape[1] - 1)\n",
    "    print('Expected chi-square under independence',df)\n",
    "    print('Ratio (observed/expected)', chi2_stat/df)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac8e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
