{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bc86ba",
   "metadata": {},
   "source": [
    "# Relational Analysis\n",
    "\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "Data sources for this analysis are described below.\n",
    "\n",
    "### Corpus\n",
    "\n",
    "The [corpus](https://www.constitutueproject.org) comprises the set of in-force national constitutions compiled by the CCP.  \n",
    "\n",
    "### Ontologies\n",
    "\n",
    "#### Reference\n",
    "\n",
    "Our reference ontology is:\n",
    "\n",
    "- CCP-FACET: A faceted version of the [CCP ontology](https://www.constitutueproject.org).\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "Our comparison ontologies in this analysis are:\n",
    "\n",
    "- IDEA-GLO: [International IDEA Database Glossary](https://www.idea.int/data-tools)\n",
    "- NC-DCC: Núcleo Constituyente,Diccionario Constitucional Chileno, Second Edition\n",
    "\n",
    "All ontologies were formatted to conform to the Sartori Network's ontology specification of:\n",
    "\n",
    "- One topic per row\n",
    "- A minimum column set comprising the following fields:\n",
    "    - key: a short topic identifier. If this is not provided by the ontology owner, then an integer is used.\n",
    "    - label: a short human-readable text label.\n",
    "    - description: a longer descriptive text.\n",
    "- A first row containing the column names: `key`, `label`, `description`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efb3f0",
   "metadata": {},
   "source": [
    "## Initialialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696b405",
   "metadata": {},
   "source": [
    "### Load code and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715638f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Roy Gardner'\n",
    "__copyright__   = 'Copyright 2025, Roy and Sally Gardner'\n",
    "\n",
    "%run ./_library/packages.py\n",
    "%run ./_library/utilities.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfca9893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation started…\n",
      "Finished initialisation.\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/'\n",
    "\n",
    "exclusion_list = []\n",
    "_,_,files = next(os.walk(model_path))\n",
    "for file in files:\n",
    "    if '_encodings.json' in file:\n",
    "        exclusion_list.append(file)\n",
    "\n",
    "model_dict = initialise(model_path,exclusion_list=exclusion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8dbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b6eff3",
   "metadata": {},
   "source": [
    "### Map segments onto tagged topics\n",
    "\n",
    "This gives us a human-coded segment-topic map from which we can check for human coding of segments that have no semantic relationship to CCP reference topics but are semantically similar to a comparison topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042db02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the sat_segments_dict\n",
    "\n",
    "segments_lookup = {}\n",
    "for k,v in model_dict['sat_segments_dict'].items():\n",
    "    for segment_id in v:\n",
    "        if segment_id in segments_lookup:\n",
    "            segments_lookup[segment_id].append(k)\n",
    "        else:\n",
    "            segments_lookup[segment_id] = [k]\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7370f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2bfedd9",
   "metadata": {},
   "source": [
    "## Topic Discovery\n",
    "\n",
    "### Rationale\n",
    "\n",
    "The methodology looks at the semantic similarities between topics in a pair of ontologies and the sections (referred to as segments) of a corpus of national constitutions. One of the ontologies is a reference ontology that is aligned with the corpus — in the analysis here the Comparative Constitutions Project (CCP) ontology. The other ontology is referred to as the comparison ontology.\n",
    "\n",
    "The objective is to find segments that are similar to comparison topics but not to reference topics. We use a comparison ontology to audit the reference ontology in order to identify gaps in the coverage of the reference ontology. \n",
    "\n",
    "Comparison topics that capture segments that the reference ontology misses may be candidates for inclusion in the reference ontology. If a candidate comparison topic is considered semantically similar to an existing reference topic, then segments have been missed by manual coding.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "The methodology is based on maniupulation of semantic similarity matrices constructed during ontology and corpus processing — see the codebase in the `processing` folder. The similarity matrices can be found in the `model` folder in the following files:\n",
    "- CCP-FACET_topic_segment_matrix.json: CCP-FACET reference topics in rows, constitution segments in columns.\n",
    "- IDEA-GLO_topic_segment_matrix.json: IDEA-GLO topics in rows, constitution segments in columns.\n",
    "- NC-DCC_topic_segment_matrix.json: NC-DCC topics in rows, constitution segments in columns.\n",
    "\n",
    "Each matrix has the topics of an ontology in rows, and the segments of the corpus in columns. Cells contain the semantic similarity score of a topic-segment pair. Similarity scores are calculated as the angular distance between the encoding vectors of topic and segment text where the topic text is the concatenated label and description. Encoding vectors were generating using Google's multilingual Universal Sentence Encoder version 3.\n",
    "\n",
    "\n",
    "#### Process\n",
    "\n",
    "1. Let the CCP-FACET matrix be $\\mathbf{A}$.\n",
    "2. Threshold and binarise $\\mathbf{A}$ to produce $\\mathbf{B}$.\n",
    "3. Let the comparison matrix be $\\mathbf{C}$.\n",
    "4. Threshold and binarise $\\mathbf{C}$ to produce $\\mathbf{D}$.\n",
    "5. Let $\\mathbf{E}=\\mathbf{DB}^T$.\n",
    "\n",
    "$\\mathbf{E}$ contains a co-occurrence matrix with comparison topics in rows and reference topics in columns. Cells values contain the number of segments that are at or above threshold for a given topic pair, i.e., the number of segments that are semantically similar to both topics.\n",
    "\n",
    "Next:\n",
    "\n",
    "Find rows in $\\mathbf{E}$ that contain only zeros. These rows are comparison topics that have no segments in common with any of the reference topics. For each such comparison topic:\n",
    "1. Recover any semantically similar segments from $\\mathbf{D}$.\n",
    "2. For every segment recovered from $\\mathbf{D}$, ensure that the segment's column in $\\mathbf{B}$ contains only zeros.\n",
    "\n",
    "We now have a set of comparison topics each of which is semantically similar to a set of corpus segments that are not semantically similar to any reference topics. As a further step, any manually tagged segments in the segment sets are identified. \n",
    "\n",
    "#### Outputs\n",
    "\n",
    "For a selected comparison ontology the following files are generated:\n",
    "\n",
    "1. `<ontology_identifier>_candidate_data.csv`\n",
    "    - Each row contains a candidate topic and a semantically similar constitution segment.\n",
    "    - Candidate topics repeat if the topic is semantically similar to more than one segment.\n",
    "    - Columns are:\n",
    "        - `comparison_topic_key`: the comparison topic key.\n",
    "        - `comparison_topic_text`: the topic text (concatenated label and description) used to generate the encoding vector.\n",
    "        - `segment_id`: the ID of a semantically similar segment. Contains the constitution identifier.\n",
    "        - `segment_text`: the text of segment.\n",
    "        - `tagged_ccp_topics`: a list of manually tagged CCP topic codes for a segment.\n",
    "2. `<ontology_identifier>_candidate_list.csv`\n",
    "    - Each row contains a candidate topic.\n",
    "    - Columns are:\n",
    "        - `key`\n",
    "        - `label`\n",
    "        - `description`\n",
    "\n",
    "Sample outputs at a threshold of 0.7 are present in the `outputs` folder.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Candidate topics may provide evidence for:\n",
    "\n",
    "- New topics for the reference ontology where the semantic distance between a candidate topic and existing topics is high.\n",
    "- Segments have been missed by manual tagging. This may be the case if a candidate topic is judged similar to an existing reference topic and/or a segment is manually tagged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bcb8f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4b92f0",
   "metadata": {},
   "source": [
    "### Generate user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf56ea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e494e8c51e648f9ba9342b9252d1d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='REFERENCE ONTOLOGY: CCP-FACET/Faceted/Comparative Constitutions Project')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da142161d834739a6b650f476ef0a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SELECT A COMPARISON ONTOLOGY:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2680028e074abca1709be95a9b771e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Ontology:', layout=Layout(width='800px'), options=('FJC-IDB/Appeals Integrated Database/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3111102272546e490c9db349bc578bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SET THE SEMANTIC SIMILARITY THRESHOLD:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581eb8fc14b5449faaf309ea024e3c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.7, continuous_update=False, description='Threshold:', layout=Layout(width='800px'), max=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb823bbecb83424187401d7f4f4ce26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Apply Choices', style=ButtonStyle(), tooltip='Click to apply choices')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98159c96f88d4bcd83f86b52a51e6cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_choice_dict = init_discovery_choice_dict()\n",
    "discovery_interface(discovery_choice_dict,model_dict['ontologies_dict'],0.70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63d8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9429f078",
   "metadata": {},
   "source": [
    "### Run with selection from interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e87bc8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated 220 segments for IDEA-GLO\n",
      "Candidate topics and segments exported to CSV file: ./outputs/IDEA-GLO_candidate_data.csv\n",
      "Candidate topic list exported to CSV file: ./outputs/IDEA-GLO_candidate_list.csv\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "threshold = discovery_choice_dict['threshold']\n",
    "reference_label = discovery_choice_dict['reference']\n",
    "comparison_label = discovery_choice_dict['comparison']\n",
    "\n",
    "\n",
    "# Threshold and binarise the topic-segment matrix of the reference ontology\n",
    "A = np.array(model_dict[f'{reference_label}_topic_segment_matrix'])\n",
    "B = np.where(A>=threshold,1,0).astype(int)\n",
    "\n",
    "# Define the data structures for the comparison ontologies\n",
    "comparison_matrix = model_dict[f'{comparison_label}_topic_segment_matrix']\n",
    "comparison_dict = model_dict[f'{comparison_label}_topics_dict']\n",
    "\n",
    "# Get the topic keys for the comparison ontology\n",
    "comp_keys = [k for k,v in comparison_dict.items()]\n",
    "# Get the topic text for the comparison ontology\n",
    "comp_text = [v['encoded_text'] for k,v in comparison_dict.items()]\n",
    "\n",
    "# Get the topic-segment matrix for our comparison ontology\n",
    "C = np.array(comparison_matrix)\n",
    "# Threshold and binarise\n",
    "D = np.where(C>=threshold,1,0).astype(int)\n",
    "\n",
    "# Co-occurrence matrix with comparison topics in rows and reference topics in columns\n",
    "E = np.matmul(D,B.T)\n",
    "\n",
    "# Use to collect segments that are semantically similar to a comparison topic\n",
    "segments_set = []\n",
    "\n",
    "csv_row_list = []\n",
    "header = []\n",
    "header.append('comparison_topic_key')\n",
    "header.append('comparison_topic_text')\n",
    "header.append('segment_id')\n",
    "header.append('segment_text')\n",
    "header.append('tagged_ccp_topics')\n",
    "csv_row_list.append(header)\n",
    "\n",
    "# Iterate comparison topics searching for empty rows in the co-occurrence matrix E.\n",
    "# An empty row means that the comparison topic shares no segments with any CCP topic\n",
    "for i,row in enumerate(E):\n",
    "    if row.nonzero()[0].size == 0:\n",
    "        # Get at or above threshold segments from the topic's row in topic-segment matrix D\n",
    "        segment_indices = [j for j,v in enumerate(D[i]) if v==1]\n",
    "        if len(segment_indices) == 0:\n",
    "            # Comparison topic is not semantically similar to any segment\n",
    "            continue\n",
    "        for j in segment_indices:\n",
    "            # Iterating the comparison topic's semantically similar segments\n",
    "            csv_row = []\n",
    "            csv_row.append(comp_keys[i])\n",
    "            csv_row.append(comp_text[i])\n",
    "            segment_id = model_dict['encoded_segments'][j]\n",
    "            segments_set.append(segment_id)\n",
    "            segment_text = model_dict['segments_dict'][segment_id]['text']\n",
    "            csv_row.append(segment_id)\n",
    "            csv_row.append(segment_text)\n",
    "            # Check whether the segment has been manually tagged\n",
    "            if segment_id in segments_lookup:\n",
    "                csv_row.append(str(segments_lookup[segment_id]))\n",
    "            else:\n",
    "                csv_row.append('')\n",
    "            csv_row_list.append(csv_row)\n",
    "\n",
    "# Validate the segment set by ensuring that each segment's column in the CCP topic-segment\n",
    "# matrix comprises zeros only. This test ensures that a segment is not semantically similar to \n",
    "# a CCP topic at or above threshold.\n",
    "segments_set = list(set(segments_set))\n",
    "n = 0\n",
    "for segment_id in segments_set:\n",
    "    segment_index = model_dict['encoded_segments'].index(segment_id)\n",
    "    if B[:,segment_index].nonzero()[0].size == 0:\n",
    "        n += 1\n",
    "assert(len(segments_set)==n)       \n",
    "print('Validated',len(segments_set),'segments for',comparison_label)\n",
    "\n",
    "# Got through validation so write results to CSV file\n",
    "with open('./outputs/' + comparison_label + '_candidate_data.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(csv_row_list)\n",
    "f.close() \n",
    "print('Candidate topics and segments exported to CSV file:','./outputs/' +\\\n",
    "              comparison_label + '_candidate_data.csv')\n",
    "\n",
    "# Write list of candidate comparison topics to file\n",
    "comp_topics = sorted(list(set([row[0] for row in csv_row_list[1:]])))\n",
    "\n",
    "row_list = []\n",
    "header = []\n",
    "header.append('key')\n",
    "header.append('label')\n",
    "header.append('description')\n",
    "row_list.append(header)\n",
    "for int_key in comp_topics:\n",
    "    key = str(int_key)\n",
    "    csv_row = []\n",
    "    csv_row.append(key)\n",
    "    csv_row.append(comparison_dict[key]['Label'])\n",
    "    csv_row.append(comparison_dict[key]['Description'])\n",
    "    row_list.append(csv_row)\n",
    "\n",
    "with open('./outputs/' + comparison_label + '_candidate_list.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(row_list)\n",
    "f.close() \n",
    "print('Candidate topic list exported to CSV file:','./outputs/' + comparison_label + '_candidate_list.csv')\n",
    "print()\n",
    "    \n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71927d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa637b08",
   "metadata": {},
   "source": [
    "## Concept Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4f11958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 163596)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "ont_count = len(model_dict['ontologies_dict'])\n",
    "ont_labels = sorted(list(model_dict['ontologies_dict'].keys()))\n",
    "\n",
    "ont_segment_matrix = []\n",
    "\n",
    "for ont_label in ont_labels:\n",
    "    ont_matrix = np.array(model_dict[f'{ont_label}_topic_segment_matrix'])\n",
    "    M = np.where(ont_matrix>=threshold,1,0).astype(int)\n",
    "    marginal = np.sum(M,axis=0)\n",
    "    ont_segment_matrix.append(marginal)\n",
    "\n",
    "U = np.array(ont_segment_matrix)\n",
    "print(U.shape)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef7c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8742a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixColumnQuery:\n",
    "    def __init__(self,matrix):\n",
    "        self.matrix = matrix\n",
    "        self.n_cols = matrix.shape[1]\n",
    "    \n",
    "    def all_nonzero(self):\n",
    "        \"\"\"Find columns where all elements are non-zero\"\"\"\n",
    "        return [col for col in range(self.n_cols) \n",
    "                if np.all(self.matrix[:, col] != 0)]\n",
    "    \n",
    "    def any_nonzero(self,positions):\n",
    "        \"\"\"Find columns with non-zero values at ANY of the specified positions\"\"\"\n",
    "        return [col for col in range(self.n_cols)\n",
    "                if np.any(self.matrix[positions, col] != 0)]\n",
    "    \n",
    "    def all_positions_nonzero(self,positions):\n",
    "        \"\"\"Find columns with non-zero values at ALL specified positions\"\"\"\n",
    "        return [col for col in range(self.n_cols)\n",
    "                if np.all(self.matrix[positions, col] != 0)]\n",
    "    \n",
    "    def exactly_nonzero(self,positions):\n",
    "        \"\"\"Find columns with non-zero ONLY at specified positions (zeros elsewhere)\"\"\"\n",
    "        return [col for col in range(self.n_cols)\n",
    "                if (np.all(self.matrix[positions, col] != 0) and \n",
    "                    np.all(self.matrix[np.setdiff1d(range(7), positions), col] == 0))]\n",
    "    \n",
    "    def count_nonzero(self,count):\n",
    "        \"\"\"Find columns with exactly 'count' non-zero elements\"\"\"\n",
    "        return [col for col in range(self.n_cols)\n",
    "                if np.count_nonzero(self.matrix[:, col]) == count]\n",
    "    \n",
    "    def query(self,condition):\n",
    "        \"\"\"Flexible query with lambda function\"\"\"\n",
    "        return [col for col in range(self.n_cols)\n",
    "                if condition(self.matrix[:, col])]\n",
    "\n",
    "# Example usage:\n",
    "matrix = np.array([\n",
    "    [1, 0, 2, 1, 8],\n",
    "    [2, 1, 0, 1, 3], \n",
    "    [0, 2, 3, 1, 5],\n",
    "    [1, 0, 1, 0, 2],\n",
    "    [0, 1, 0, 1, 1],\n",
    "    [2, 0, 2, 1, 5],\n",
    "    [1, 1, 1, 0, 3]\n",
    "])\n",
    "\n",
    "\n",
    "q = MatrixColumnQuery(U)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800d993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0953684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All non-zero segments: []\n",
      "Segments with exactly 4 non-zero elements: [8227, 15295, 50126, 78849, 113698, 114046, 119620, 150989]\n",
      "\n",
      "Decide, except those involving the right to vote, all questions affecting elections, including determination of the number and location of polling places, appointment of election officials and inspectors, and registration of voters.\n",
      "[ 1  0  2  1 11  0  0]\n",
      "['CCP-FACET', 'GLOBALCIT-GLO', 'IDEA-DT', 'IDEA-GLO']\n",
      "\n",
      "Judiciary power is exercised by courts. Courts are autonomous and independent. Courts judge on the basis of the Constitution and laws and international agreements ratified in accordance with the Constitution. There is one form of organization for the judiciary. Emergency courts are prohibited. The types of courts, their spheres of competence, their establishment, abrogation, organization and composition, as well as the procedure they follow are regulated by a law adopted by a majority vote of two-thirds of the total number of Representatives.\n",
      "[1 0 0 1 2 0 4]\n",
      "['CCP-FACET', 'IDEA-DT', 'IDEA-GLO', 'STROM-IDC']\n",
      "\n",
      "\"General Elections\" or \"people elections\" means an election of a President and of the Members of Parliament representing electoral constituencies, which is held subsequent to the dissolution of Parliament;\n",
      "[2 0 2 1 8 0 0]\n",
      "['CCP-FACET', 'GLOBALCIT-GLO', 'IDEA-DT', 'IDEA-GLO']\n",
      "\n",
      "The Vice-President shall be elected by the members of an electoral college consisting of the members of both Houses of Parliament in accordance with the system of proportional representation by means of the single transferable vote and the voting at such election shall be by secret ballot.\n",
      "[ 1  0  1  1 18  0  0]\n",
      "['CCP-FACET', 'GLOBALCIT-GLO', 'IDEA-DT', 'IDEA-GLO']\n",
      "\n",
      "In the case of popular ballots the rules relating to campaign financing and advertising and access to the State media which govern the ordinary elections shall apply. Those who participate in the ballot of a party or political movement or in inter-party elections may not register for another one in the same electoral process. The result of the ballots shall be binding.\n",
      "[ 1  0  3  1 17  0  0]\n",
      "['CCP-FACET', 'GLOBALCIT-GLO', 'IDEA-DT', 'IDEA-GLO']\n",
      "\n",
      "The Judicial Government Council is the organ in charge of defining the policies of the Judicial Branch according to the law and to postulate the lists and shortlists of candidates that the Constitution orders. Also, it corresponds to the Judicial Government Council to regulate all the judicial and administrative proceedings in the judicial offices, for the aspects not anticipated by the legislator; issue the regulations of the system of judicial career and the Commission of Judicial Career, which will serve to oversee and control the career; approve the budget of the Judicial Branch to be sent to the Government; approve the judicial map; define the organic structure of the Administration of the Judicial Branch; supervise this entity, and provide reports about its performance to the Congress of the Republic.\n",
      "[1 0 0 1 2 0 4]\n",
      "['CCP-FACET', 'IDEA-DT', 'IDEA-GLO', 'STROM-IDC']\n",
      "\n",
      "Other candidacy requirements, the electoral system, and division of electoral constituencies shall be defined by law in a manner which observes fair representation of the population and governorates. Elections based on the plurality voting system or proportional list, or a combination of both at whatsoever ratio may be adopted.\n",
      "[ 1  0  0  1 17  2  0]\n",
      "['CCP-FACET', 'IDEA-DT', 'IDEA-GLO', 'JUON-CPSD']\n",
      "\n",
      "A political party, or a coalition of political parties that has the greatest number of seats in the House of Peoples' Representatives shall form the Executive and lead it.\n",
      "[2 0 0 1 3 0 4]\n",
      "['CCP-FACET', 'IDEA-DT', 'IDEA-GLO', 'STROM-IDC']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('All non-zero segments:',q.all_nonzero())\n",
    "\n",
    "count = 4\n",
    "results = q.count_nonzero(count)\n",
    "print(f'Segments with exactly {count} non-zero elements:',results)\n",
    "print()\n",
    "\n",
    "\n",
    "for segment_index in results:\n",
    "    segment_id = model_dict['encoded_segments'][segment_index]\n",
    "    segment_text = model_dict['segments_dict'][segment_id]['text']\n",
    "    print(segment_text)\n",
    "    print(U[:,segment_index])\n",
    "    print([ont_labels[i] for i,v in enumerate(U[:,segment_index]) if v > 0])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37e9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a536d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf45a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb75f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
