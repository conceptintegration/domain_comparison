{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bc86ba",
   "metadata": {},
   "source": [
    "# Topic Discovery\n",
    "\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "Data sources for this analysis are described below.\n",
    "\n",
    "### Corpus\n",
    "\n",
    "The [corpus](https://www.constitutueproject.org) comprises the set of in-force national constitutions compiled by the CCP.  \n",
    "\n",
    "### Ontologies\n",
    "\n",
    "#### Reference\n",
    "\n",
    "Our reference ontology is:\n",
    "\n",
    "- CCP-FACET: A faceted version of the [CCP ontology](https://www.constitutueproject.org).\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "Our comparison ontologies in this analysis are:\n",
    "\n",
    "- IDEA-GLO: [International IDEA Database Glossary](https://www.idea.int/data-tools)\n",
    "- NC-DCC: Núcleo Constituyente,Diccionario Constitucional Chileno, Second Edition\n",
    "\n",
    "All ontologies were formatted to conform to the Sartori Network's ontology specification of:\n",
    "\n",
    "- One topic per row\n",
    "- A minimum column set comprising the following fields:\n",
    "    - key: a short topic identifier. If this is not provided by the ontology owner, then an integer is used.\n",
    "    - label: a short human-readable text label.\n",
    "    - description: a longer descriptive text.\n",
    "- A first row containing the column names: `key`, `label`, `description`.\n",
    "\n",
    "\n",
    "## Rationale\n",
    "\n",
    "The methodology looks at the semantic similarities between topics in a pair of ontologies and the sections (referred to as segments) of a corpus of national constitutions. One of the ontologies is a reference ontology that is aligned with the corpus — in the analysis here the Comparative Constitutions Project (CCP) ontology. The other ontology is referred to as the comparison ontology.\n",
    "\n",
    "The objective is to find segments that are similar to comparison topics but not to reference topics. We use a comparison ontology to audit the reference ontology in order to identify gaps in the coverage of the reference ontology. \n",
    "\n",
    "Comparison topics that capture segments that the reference ontology misses may be candidates for inclusion in the reference ontology. If a candidate comparison topic is considered semantically similar to an existing reference topic, then segments have been missed by manual coding.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "The methodology is based on maniupulation of semantic similarity matrices constructed during ontology and corpus processing — see the codebase in the `processing` folder. The similarity matrices can be found in the `model` folder in the following files:\n",
    "- CCP-FACET_topic_segment_matrix.json: CCP-FACET reference topics in rows, constitution segments in columns.\n",
    "- IDEA-GLO_topic_segment_matrix.json: IDEA-GLO topics in rows, constitution segments in columns.\n",
    "- NC-DCC_topic_segment_matrix.json: NC-DCC topics in rows, constitution segments in columns.\n",
    "\n",
    "Each matrix has the topics of an ontology in rows, and the segments of the corpus in columns. Cells contain the semantic similarity score of a topic-segment pair. Similarity scores are calculated as the angular distance between the encoding vectors of topic and segment text where the topic text is the concatenated label and description. Encoding vectors were generating using Google's multilingual Universal Sentence Encoder version 3.\n",
    "\n",
    "\n",
    "### Process\n",
    "\n",
    "1. Let the CCP-FACET matrix be $\\mathbf{A}$.\n",
    "2. Threshold and binarise $\\mathbf{A}$ to produce $\\mathbf{B}$.\n",
    "3. Let the comparison matrix be $\\mathbf{C}$.\n",
    "4. Threshold and binarise $\\mathbf{C}$ to produce $\\mathbf{D}$.\n",
    "5. Let $\\mathbf{E}=\\mathbf{DB}^T$.\n",
    "\n",
    "$\\mathbf{E}$ contains a co-occurrence matrix with comparison topics in rows and reference topics in columns. Cells values contain the number of segments that are at or above threshold for a given topic pair, i.e., the number of segments that are semantically similar to both topics.\n",
    "\n",
    "Next:\n",
    "\n",
    "Find rows in $\\mathbf{E}$ that contain only zeros. These rows are comparison topics that have no segments in common with any of the reference topics. For each such comparison topic:\n",
    "1. Recover any semantically similar segments from $\\mathbf{D}$.\n",
    "2. For every segment recovered from $\\mathbf{D}$, ensure that the segment's column in $\\mathbf{B}$ contains only zeros.\n",
    "\n",
    "We now have a set of comparison topics each of which is semantically similar to a set of corpus segments that are not semantically similar to any reference topics. As a further step, any manually tagged segments in the segment sets are identified. \n",
    "\n",
    "### Outputs\n",
    "\n",
    "For a selected comparison ontology the following files are generated:\n",
    "\n",
    "1. `<ontology_identifier>_candidate_data.csv`\n",
    "    - Each row contains a candidate topic and a semantically similar constitution segment.\n",
    "    - Candidate topics repeat if the topic is semantically similar to more than one segment.\n",
    "    - Columns are:\n",
    "        - `comparison_topic_key`: the comparison topic key.\n",
    "        - `comparison_topic_text`: the topic text (concatenated label and description) used to generate the encoding vector.\n",
    "        - `segment_id`: the ID of a semantically similar segment. Contains the constitution identifier.\n",
    "        - `segment_text`: the text of segment.\n",
    "        - `tagged_ccp_topics`: a list of manually tagged CCP topic codes for a segment.\n",
    "2. `<ontology_identifier>_candidate_list.csv`\n",
    "    - Each row contains a candidate topic.\n",
    "    - Columns are:\n",
    "        - `key`\n",
    "        - `label`\n",
    "        - `description`\n",
    "\n",
    "Sample outputs at a threshold of 0.7 are present in the `outputs` folder.\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "Candidate topics may provide evidence for:\n",
    "\n",
    "- New topics for the reference ontology where the semantic distance between a candidate topic and existing topics is high.\n",
    "- Segments have been missed by manual tagging. This may be the case if a candidate topic is judged similar to an existing reference topic and/or a segment is manually tagged.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f4ef1",
   "metadata": {},
   "source": [
    "## Initialialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696b405",
   "metadata": {},
   "source": [
    "### Load code and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715638f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Roy Gardner'\n",
    "__copyright__   = 'Copyright 2025, Roy and Sally Gardner'\n",
    "\n",
    "%run ./_library/packages.py\n",
    "%run ./_library/utilities.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d57176",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model/'\n",
    "\n",
    "exclusion_list = []\n",
    "_,_,files = next(os.walk(model_path))\n",
    "for file in files:\n",
    "    if '_encodings.json' in file:\n",
    "        exclusion_list.append(file)\n",
    "\n",
    "model_dict = initialise(model_path,exclusion_list=exclusion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8dbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b6eff3",
   "metadata": {},
   "source": [
    "### Map segments onto tagged topics\n",
    "\n",
    "This gives us a human-coded segment-topic map from which we can check for human coding of segments that have no semantic relationship to CCP reference topics but are semantically similar to a comparison topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042db02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the sat_segments_dict\n",
    "\n",
    "segments_lookup = {}\n",
    "for k,v in model_dict['sat_segments_dict'].items():\n",
    "    for segment_id in v:\n",
    "        if segment_id in segments_lookup:\n",
    "            segments_lookup[segment_id].append(k)\n",
    "        else:\n",
    "            segments_lookup[segment_id] = [k]\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7370f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaa5e92d",
   "metadata": {},
   "source": [
    "## Generate user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a340094",
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_choice_dict = init_discovery_choice_dict()\n",
    "discovery_interface(discovery_choice_dict,model_dict['ontologies_dict'],0.70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4757abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29a89efd",
   "metadata": {},
   "source": [
    "## Run with selection from interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = discovery_choice_dict['threshold']\n",
    "reference_label = discovery_choice_dict['reference']\n",
    "comparison_label = discovery_choice_dict['comparison']\n",
    "\n",
    "\n",
    "# Threshold and binarise the topic-segment matrix of the reference ontology\n",
    "A = np.array(model_dict[f'{reference_label}_topic_segment_matrix'])\n",
    "B = np.where(A>=threshold,1,0).astype(int)\n",
    "\n",
    "# Define the data structures for the comparison ontologies\n",
    "comparison_matrix = model_dict[f'{comparison_label}_topic_segment_matrix']\n",
    "comparison_dict = model_dict[f'{comparison_label}_topics_dict']\n",
    "\n",
    "# Get the topic keys for the comparison ontology\n",
    "comp_keys = [k for k,v in comparison_dict.items()]\n",
    "# Get the topic text for the comparison ontology\n",
    "comp_text = [v['encoded_text'] for k,v in comparison_dict.items()]\n",
    "\n",
    "# Get the topic-segment matrix for our comparison ontology\n",
    "C = np.array(comparison_matrix)\n",
    "# Threshold and binarise\n",
    "D = np.where(C>=threshold,1,0).astype(int)\n",
    "\n",
    "# Co-occurrence matrix with comparison topics in rows and reference topics in columns\n",
    "E = np.matmul(D,B.T)\n",
    "\n",
    "# Use to collect segments that are semantically similar to a comparison topic\n",
    "segments_set = []\n",
    "\n",
    "csv_row_list = []\n",
    "header = []\n",
    "header.append('comparison_topic_key')\n",
    "header.append('comparison_topic_text')\n",
    "header.append('segment_id')\n",
    "header.append('segment_text')\n",
    "header.append('tagged_ccp_topics')\n",
    "csv_row_list.append(header)\n",
    "\n",
    "# Iterate comparison topics searching for empty rows in the co-occurrence matrix E.\n",
    "# An empty row means that the comparison topic shares no segments with any CCP topic\n",
    "for i,row in enumerate(E):\n",
    "    if row.nonzero()[0].size == 0:\n",
    "        # Get at or above threshold segments from the topic's row in topic-segment matrix D\n",
    "        segment_indices = [j for j,v in enumerate(D[i]) if v==1]\n",
    "        if len(segment_indices) == 0:\n",
    "            # Comparison topic is not semantically similar to any segment\n",
    "            continue\n",
    "        for j in segment_indices:\n",
    "            # Iterating the comparison topic's semantically similar segments\n",
    "            csv_row = []\n",
    "            csv_row.append(comp_keys[i])\n",
    "            csv_row.append(comp_text[i])\n",
    "            segment_id = model_dict['encoded_segments'][j]\n",
    "            segments_set.append(segment_id)\n",
    "            segment_text = model_dict['segments_dict'][segment_id]['text']\n",
    "            csv_row.append(segment_id)\n",
    "            csv_row.append(segment_text)\n",
    "            # Check whether the segment has been manually tagged\n",
    "            if segment_id in segments_lookup:\n",
    "                csv_row.append(str(segments_lookup[segment_id]))\n",
    "            else:\n",
    "                csv_row.append('')\n",
    "            csv_row_list.append(csv_row)\n",
    "\n",
    "# Validate the segment set by ensuring that each segment's column in the CCP topic-segment\n",
    "# matrix comprises zeros only. This test ensures that a segment is not semantically similar to \n",
    "# a CCP topic at or above threshold.\n",
    "segments_set = list(set(segments_set))\n",
    "n = 0\n",
    "for segment_id in segments_set:\n",
    "    segment_index = model_dict['encoded_segments'].index(segment_id)\n",
    "    if B[:,segment_index].nonzero()[0].size == 0:\n",
    "        n += 1\n",
    "assert(len(segments_set)==n)       \n",
    "print('Validated',len(segments_set),'segments for',comparison_label)\n",
    "\n",
    "# Got through validation so write results to CSV file\n",
    "with open('./outputs/' + comparison_label + '_candidate_data.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(csv_row_list)\n",
    "f.close() \n",
    "print('Candidate topics and segments exported to CSV file:','./outputs/' +\\\n",
    "              comparison_label + '_candidate_data.csv')\n",
    "\n",
    "# Write list of candidate comparison topics to file\n",
    "comp_topics = sorted(list(set([row[0] for row in csv_row_list[1:]])))\n",
    "\n",
    "row_list = []\n",
    "header = []\n",
    "header.append('key')\n",
    "header.append('label')\n",
    "header.append('description')\n",
    "row_list.append(header)\n",
    "for int_key in comp_topics:\n",
    "    key = str(int_key)\n",
    "    csv_row = []\n",
    "    csv_row.append(key)\n",
    "    csv_row.append(comparison_dict[key]['Label'])\n",
    "    csv_row.append(comparison_dict[key]['Description'])\n",
    "    row_list.append(csv_row)\n",
    "\n",
    "with open('./outputs/' + comparison_label + '_candidate_list.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(row_list)\n",
    "f.close() \n",
    "print('Candidate topic list exported to CSV file:','./outputs/' + comparison_label + '_candidate_list.csv')\n",
    "print()\n",
    "    \n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5873e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
